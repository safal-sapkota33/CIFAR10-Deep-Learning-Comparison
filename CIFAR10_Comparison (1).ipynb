{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 Deep Learning Comparison: NN vs AlexNet vs TinyVGG"
      ],
      "metadata": {
        "id": "9hccHQNfOL-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqTm5wcn43Kw",
        "outputId": "2c84b01b-88ef-49c2-ff16-6c71bdb708f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targeting device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Targeting device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook evaluates three different neural network architectures on the CIFAR-10 dataset. We compare a basic Fully Connected Neural Network (SimpleNN), a historically significant CNN (AlexNet), and a modern efficient architecture (TinyVGG)."
      ],
      "metadata": {
        "id": "d4x3L11NOQBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preparation and Normalization"
      ],
      "metadata": {
        "id": "bbRvZ0t0OTgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the processing steps\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "# 2. Download the datasets\n",
        "# Training data (50,000 images)\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# Testing data (10,000 images - used to grade the model later)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# 3. Create the DataLoaders (The \"conveyor belt\" for the GPU)\n",
        "# batch_size=64 means we feed 64 images at a time to the GPU\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# The 10 categories in CIFAR-10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print(f\"Data is ready! {len(train_set)} training images and {len(test_set)} testing images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rRe6t_95zvZ",
        "outputId": "f0e6a2a7-12e9-4670-a507-67ece95d3ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data is ready! 50000 training images and 10000 testing images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reasoning: I applied normalization using the mean and standard deviation specific to the CIFAR-10 dataset. This scales the input data to a standard distribution, which prevents gradients from exploding or vanishing and helps the optimizer converge more smoothly."
      ],
      "metadata": {
        "id": "gCYfayHwOVrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "# Print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "ajs-bcFF6DC7",
        "outputId": "402d2e22-e846-4b71-81bc-6271002df845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.695148..1.8768656].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plane cat   ship  horse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Baseline Model: Simple Neural Network (Linear)"
      ],
      "metadata": {
        "id": "-HcPOHpAOeKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(3*32*32, 512), # Input: 3072, Output: 512\n",
        "            nn.ReLU(),               # Activation function\n",
        "            nn.Linear(512, 256),     # Hidden layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)       # Final Output: 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.fc_layers(x)\n",
        "        return logits\n",
        "\n",
        "# Initialize and move to GPU\n",
        "model_nn = SimpleNN().to(device)\n",
        "print(model_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Oi3B-OH-aKx",
        "outputId": "663a8743-33f7-4710-e4a1-1918e400292d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc_layers): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model serves as our baseline. It flattens the $32 \\times 32 \\times 3$ image into a single vector of 3072 values. While easy to implement, this model ignores the spatial relationship between pixels."
      ],
      "metadata": {
        "id": "TIbqvXfuOjVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    model.train() # Set model to training mode\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            # Move data to GPU\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 2. Backward pass and optimization\n",
        "            optimizer.zero_grad() # Clear old gradients\n",
        "            loss.backward()      # Calculate new gradients\n",
        "            optimizer.step()      # Update weights\n",
        "\n",
        "            # Calculate accuracy for this batch\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        epoch_acc = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {running_loss/len(train_loader):.4f} - Acc: {epoch_acc:.2f}%\")\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "    print(f\"Total Training Time: {duration:.2f} seconds\")\n",
        "    return duration"
      ],
      "metadata": {
        "id": "ZfKl0oS6-jE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Training Strategy"
      ],
      "metadata": {
        "id": "X7CoQvWMPdmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training SimpleNN...\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_nn = optim.Adam(model_nn.parameters(), lr=0.001)\n",
        "\n",
        "nn_time = train_model(model_nn, train_loader, criterion, optimizer_nn, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv-Eib2Y-uBL",
        "outputId": "aff29a4c-c8ad-41ac-b69a-2fd9a9d70b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SimpleNN...\n",
            "Epoch [1/5] - Loss: 1.6646 - Acc: 41.00%\n",
            "Epoch [2/5] - Loss: 1.4704 - Acc: 48.17%\n",
            "Epoch [3/5] - Loss: 1.3720 - Acc: 51.56%\n",
            "Epoch [4/5] - Loss: 1.2995 - Acc: 54.00%\n",
            "Epoch [5/5] - Loss: 1.2266 - Acc: 56.69%\n",
            "Total Training Time: 65.45 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Adapted AlexNet for CIFAR-10"
      ],
      "metadata": {
        "id": "77yoziKHOoDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNetCIFAR(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNetCIFAR, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # We use a 3x3 kernel here because a 11x11 (original) is too big for 32x32 images\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 4 * 4, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Now initialize it\n",
        "model_alexnet = AlexNetCIFAR().to(device)\n",
        "print(\"AlexNet blueprint loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwaP5nA6_W02",
        "outputId": "a04d979e-bc7a-4134-b7cf-2319c621b463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet blueprint loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rchitectural Modifications: The original AlexNet was designed for $224 \\times 224$ images. For CIFAR-10 ($32 \\times 32$), I modified the first convolutional layer to use a $3 \\times 3$ kernel with a stride of 1."
      ],
      "metadata": {
        "id": "PlVkfb3jOtzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Training Strategy"
      ],
      "metadata": {
        "id": "0P5HkGdcP7jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize AlexNet (Ensure you ran the class definition cell earlier)\n",
        "model_alexnet = AlexNetCIFAR().to(device)\n",
        "\n",
        "print(\"\\nTraining AlexNet...\")\n",
        "optimizer_alex = optim.Adam(model_alexnet.parameters(), lr=0.001)\n",
        "\n",
        "# Training for 5 epochs\n",
        "alex_time = train_model(model_alexnet, train_loader, criterion, optimizer_alex, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-k4YyPk_ek3",
        "outputId": "dd73b65a-e1c7-4266-db7f-23a31d7f6aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training AlexNet...\n",
            "Epoch [1/5] - Loss: 1.6196 - Acc: 38.96%\n",
            "Epoch [2/5] - Loss: 1.2186 - Acc: 56.17%\n",
            "Epoch [3/5] - Loss: 1.0304 - Acc: 63.59%\n",
            "Epoch [4/5] - Loss: 0.9121 - Acc: 68.06%\n",
            "Epoch [5/5] - Loss: 0.8264 - Acc: 71.27%\n",
            "Total Training Time: 106.52 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. TinyVGG: Simplicity and Efficiency"
      ],
      "metadata": {
        "id": "DgxpVeSKOwvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # 32x32 -> MaxPool -> 16x16 -> MaxPool -> 8x8\n",
        "            nn.Linear(in_features=hidden_units * 8 * 8,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "model_tinyvgg = TinyVGG(input_shape=3, hidden_units=10, output_shape=10).to(device)\n",
        "print(\"TinyVGG model initialized!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC5OlcXoAO00",
        "outputId": "919d702b-1f29-4ce6-9c89-153ef4680fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TinyVGG model initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TinyVGG is a streamlined CNN that uses small $3 \\times 3$ filters in repeated blocks. It is designed to demonstrate that a well-structured CNN can achieve high accuracy with a very small number of parameters compared to larger models."
      ],
      "metadata": {
        "id": "DEAfE2_cOzfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Training Strategy"
      ],
      "metadata": {
        "id": "flOJFmO-PniB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining TinyVGG...\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_vgg = optim.Adam(model_tinyvgg.parameters(), lr=0.001)\n",
        "\n",
        "# Training for 5 epochs\n",
        "vgg_time = train_model(model_tinyvgg, train_loader, criterion, optimizer_vgg, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdRh8tldAR38",
        "outputId": "8c8922b6-5ae7-44c4-b046-7802844f7326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training TinyVGG...\n",
            "Epoch [1/5] - Loss: 1.6230 - Acc: 41.54%\n",
            "Epoch [2/5] - Loss: 1.3049 - Acc: 53.48%\n",
            "Epoch [3/5] - Loss: 1.1927 - Acc: 57.64%\n",
            "Epoch [4/5] - Loss: 1.1182 - Acc: 60.46%\n",
            "Epoch [5/5] - Loss: 1.0629 - Acc: 62.49%\n",
            "Total Training Time: 69.46 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Discussion and Conclusions"
      ],
      "metadata": {
        "id": "kcii2OaRPuQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def evaluate_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Calculate final accuracies on the TEST set (data the models haven't seen)\n",
        "nn_test_acc = evaluate_accuracy(model_nn, test_loader)\n",
        "alex_test_acc = evaluate_accuracy(model_alexnet, test_loader)\n",
        "vgg_test_acc = evaluate_accuracy(model_tinyvgg, test_loader)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"{'Model':<12} | {'Accuracy':<10} | {'Parameters':<12} | {'Time':<10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'SimpleNN':<12} | {nn_test_acc:>8.2f}% | {count_parameters(model_nn):>12,d} | {nn_time:>8.2f}s\")\n",
        "print(f\"{'AlexNet':<12} | {alex_test_acc:>8.2f}% | {count_parameters(model_alexnet):>12,d} | {alex_time:>8.2f}s\")\n",
        "print(f\"{'TinyVGG':<12} | {vgg_test_acc:>8.2f}% | {count_parameters(model_tinyvgg):>12,d} | {vgg_time:>8.2f}s\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY7yWmDqAmMQ",
        "outputId": "c09054ff-ecd9-4724-f17f-7b43aa7b1d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Model        | Accuracy   | Parameters   | Time      \n",
            "--------------------------------------------------\n",
            "SimpleNN     |    51.21% |    1,707,274 |    65.45s\n",
            "AlexNet      |    71.77% |   35,855,178 |   106.52s\n",
            "TinyVGG      |    61.67% |        9,420 |    69.46s\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Discussion and Conclusions\n",
        "1. Model Comparison & Results\n",
        "Our experiment reveals a clear trade-off between model complexity and classification performance:\n",
        "\n",
        "SimpleNN (~51% Accuracy): Struggled with the spatial complexity of images despite having 1.7M parameters. This proves that fully connected layers are inefficient for raw pixel data.\n",
        "\n",
        "AlexNet (~71% Accuracy): The top performer. Its depth and 35M parameters allow it to learn complex feature hierarchies, though it is the \"heaviest\" and slowest model.\n",
        "\n",
        "TinyVGG (~61% Accuracy): The efficiency winner. It outperformed the SimpleNN with only 9,420 parameters, demonstrating that convolutional layers are far superior for image tasks.\n",
        "\n",
        "2. AlexNet’s Revolutionary Improvements\n",
        "Following the 2012 Krizhevsky et al. paper, AlexNet introduced three key techniques that outperformed predecessors like LeNet:\n",
        "\n",
        "ReLU Activation: Solved the vanishing gradient problem, allowing the model to train 6x faster than those using Sigmoid.\n",
        "\n",
        "Dropout: Applied to fully connected layers to prevent overfitting in such a high-parameter model.\n",
        "\n",
        "Overlapping Pooling: Reduced the error rate by capturing more robust spatial information compared to traditional pooling.\n",
        "\n",
        "3. Metric Selection: Why Recall?\n",
        "While Accuracy is suitable for the balanced CIFAR-10 dataset, Recall is critical in safety-sensitive fields. For example, in autonomous driving, high Recall for \"Truck\" detection is mandatory; missing a vehicle (False Negative) results in a collision, whereas a False Positive (Precision error) only results in safe, unnecessary braking.\n",
        "\n",
        "## Conclusion\n",
        "While deep networks like AlexNet offer maximum accuracy, TinyVGG proves that architectural efficiency is vital for resource-constrained environments. Ultimately, the shift from linear layers to convolutional blocks is the defining factor in high-performance image classification."
      ],
      "metadata": {
        "id": "P7j1p6OHQRC6"
      }
    }
  ]
}